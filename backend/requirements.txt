# Backend dependencies for Llama 3.3 70B Chat API

# LLM Engine
llama-cpp-python>=0.2.90

# HuggingFace for model downloads
huggingface_hub>=0.20.0

# FastAPI server
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
pydantic>=2.0.0

# Utilities
tqdm>=4.66.0
numpy>=1.24.0
